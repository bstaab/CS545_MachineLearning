{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1, Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Brent Staab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first assignment, we are applying python code that performs gradient descent to fit several models to the air quality data discussed in the lecture during the first week.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement (or copy from lecture notes if available) the following functions:\n",
    "\n",
    "    * `linear_model(X, W)`:\n",
    "        * Given\n",
    "            * `X`, an N x 1 numpy array of input samples\n",
    "            * `W`, a 2 x 1 numpy array of weight values, with the first weight being the bias, or y-intercept, weight\n",
    "        * Return\n",
    "            * an N x 1 numpy array of the linear model's predicted outputs for each sample in `X`.\n",
    "        \n",
    "    * `linear_model_gradient(X, T, W)`:\n",
    "        * Given\n",
    "            * `X`, an N x 1 numpy array of input samples\n",
    "            * `T`, an N x 1 numpy array of correct outputs for each input sample\n",
    "            * `W`, a 2 x 1 numpy array of weight values, with the first weight being the bias, or y-intercept, weight\n",
    "        * Return\n",
    "            * an 2 x 1 numpy array of the gradient of the mean squared error function with respect to each weight.\n",
    "\n",
    "    * `quadratic_model(X, W)`:\n",
    "        * Given\n",
    "            * `X`, an N x 1 numpy array of input samples\n",
    "            * `W`, a 3 x 1 numpy array of weight values, ordered as the bias weight, the weight for `X`, and the weight for `X**2` \n",
    "        * Return\n",
    "            * an N x 1 numpy array of the quadratic model's predicted outputs for each sample in `X`.\n",
    "        \n",
    "    * `quadratic_model_gradient(X, T, W)`:\n",
    "        * Given\n",
    "            * `X`, an N x 1 numpy array of input samples\n",
    "            * `T`, an N x 1 numpy array of correct outputs for each input sample\n",
    "            * `W`, a 3 x 1 numpy array of weight values, ordered as for `quadratic_model`\n",
    "        * Return\n",
    "            * an 3 x 1 numpy array of the gradient of the mean squared error function with respect to each weight.\n",
    "\n",
    "    * `quartic_model(X, W)`:\n",
    "        * Given\n",
    "            * `X`, an N x 1 numpy array of input samples\n",
    "            * `W`, a 5 x 1 numpy array of weight values, ordered as the bias weight, the weight for `X`, the weight for `X**2`, the weight for `X**3`, and the weight for `X**4`\n",
    "        * Return\n",
    "            * an N x 1 numpy array of the quartic model's predicted outputs for each sample in `X`.\n",
    "        \n",
    "    * `quartic_model_gradient(X, T, W)`:\n",
    "        * Given\n",
    "            * `X`, an N x 1 numpy array of input samples\n",
    "            * `T`, an N x 1 numpy array of correct outputs for each input sample\n",
    "            * `W`, a 5 x 1 numpy array of weight values, ordered as for `quartic_model`\n",
    "        * Return\n",
    "            * an 5 x 1 numpy array of the gradient of the mean squared error function with respect to each weight.\n",
    "\n",
    "\n",
    "2. Download the air quality data and prepare the `X` and `T` matrices as shown in the following code cells. This is a little different than what was done in class. Plot `CO(GT)` air quality versus the hour of the day to verify you have prepared the data correctly.\n",
    "\n",
    "3. Use the `gradient_descent_adam` function defined in the lecture notes to find the best weights for the linear model, as illustrated in lecture.  Plot the RMSE versus iterations, plot the weights versus the number of steps, and plot the air quality versus hour of the day again and superimpose the linear model on the same graph.  All of this is illustrated here using a `cubic_model`.  Once this is working, copy and paste the code cells for each model and train each model with at least five different learning rates, from 1.e-2, to 1.e-10 to find rates that result in the lowest error.  Do not change the number of iterations steps.  Include the code and results for each. Discuss in markdown cells the best learning rate values and errors you get for each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import code needed in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Implement functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(X, W):\n",
    "    # W is column vector\n",
    "    return X @ W[1:, :] + W[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_dYdW(X, T, W):\n",
    "    # One row per sample in X,T.  One column per W component.\n",
    "    # For first one, is constant 1.\n",
    "    # For second one, is value of X\n",
    "    return np.insert(X, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_dEdY(X, T, W):\n",
    "    Y = linear_model(X, W)\n",
    "    return -2 * (T - Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.K.A dEdW\n",
    "def linear_model_gradient(X, T, W):\n",
    "    result = linear_model_dEdY(X, T, W).T @ linear_model_dYdW(X, T, W) / (X.shape[0])\n",
    "    return result.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_model(X, W):\n",
    "    # W is column vector\n",
    "    n_columns = X.shape[1]\n",
    "    linear_part = X @ W[1:n_columns + 1, :] + W[0,:]\n",
    "    nonlinear_part = X**2 @ W[n_columns + 1:n_columns + 2, :]\n",
    "    return nonlinear_part + linear_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_model_dYdW(X, T, W):\n",
    "    # One row per sample in X,T.  One column per W component.\n",
    "    # For first one, is constant 1.\n",
    "    # For second one, is value of X\n",
    "    linear_part = np.insert(X, 0, 1, axis=1)\n",
    "    nonlinear_part = X**2\n",
    "    return np.hstack((linear_part, nonlinear_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_model_dEdY(X, T, W):\n",
    "    Y = quadratic_model(X, W)\n",
    "    return -2 * (T - Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.K.A dEdW\n",
    "def quadratic_model_gradient(X, T, W):\n",
    "    result = quadratic_model_dEdY(X, T, W).T @ quadratic_model_dYdW(X, T, W) / (X.shape[0])\n",
    "    return result.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From A1 notebook - Don't modify\n",
    "def cubic_model(X, W):\n",
    "    return np.hstack((X, X**2, X**3)) @ W[1:, :] + W[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From A1 notebook - Don't modify\n",
    "def cubic_model_gradient(X, T, W):\n",
    "    dEdY = -2 * (T - cubic_model(X, W))\n",
    "    all_but_bias = np.hstack((X, X**2, X**3))\n",
    "    dYdW = np.insert(all_but_bias, 0, 1, axis=1)\n",
    "    result = dEdY.T @ dYdW / X.shape[0]\n",
    "    return result.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartic_model(X, W):\n",
    "    return np.hstack((X, X**2, X**3, X**4)) @ W[1:, :] + W[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX/VERIFY\n",
    "def quartic_model_gradient(X, T, W):\n",
    "    dEdY = -2 * (T - quartic_model(X, W))\n",
    "    all_but_bias = np.hstack((X, X**2, X**3, X**4))\n",
    "    dYdW = np.insert(all_but_bias, 0, 1, axis=1)\n",
    "    result = dEdY.T @ dYdW / X.shape[0]\n",
    "    return result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
    "T = (((X - 5) * 0.05 +  (X * 0.2) **5) / 5.0 - 5.5) / 6\n",
    "W = np.array([1, 2, -3, 1.5, 0.3]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016617411613005652"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = quartic_model_gradient(X, T, W)\n",
    "error_sequence[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(model, X, T, W):\n",
    "    Y = model(X, W)\n",
    "    return np.sqrt(np.mean((T - Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_adam(model_f, gradient_f, rmse_f, X, T, W, rho, n_steps=1):\n",
    "    # Commonly used parameter values\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "    m = 0\n",
    "    v = 0\n",
    "    \n",
    "    error_sequence = []\n",
    "    W_sequence = []\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        error_sequence.append(rmse_f(model_f, X, T, W))\n",
    "        W_sequence.append(W.flatten())\n",
    "        \n",
    "        g = gradient_f(X, T, W)\n",
    "        m = beta1 * m + (1 - beta1) * g\n",
    "        v = beta2 * v + (1 - beta2) * g * g\n",
    "        mhat = m / (1 - beta1 ** (step+1))\n",
    "        vhat = v / (1 - beta2 ** (step+1))\n",
    "        W -= rho * mhat / (np.sqrt(vhat) + epsilon)\n",
    "        \n",
    "    return W, error_sequence, W_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example from jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([0.1, 0.4, 0.7]).reshape(-1, 1)\n",
    "T = np.array([2.0, 1.0, 8.0]).reshape(-1, 1)\n",
    "W = np.array([2.0, 1.0, -0.5, 0.3]).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cubic_model_gradient(X, T, W)\n",
    "W = np.zeros((4, 1))\n",
    "rho = 1.e-1\n",
    "n_steps = 3000\n",
    "W, error_sequence, W_sequence = gradient_descent_adam(cubic_model, cubic_model_gradient, rmse, X, T, W, rho, n_steps)\n",
    "print(f'Final RMSE for rho {rho} at step {n_steps} is {np.sqrt(error_sequence[-1]):4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From grading assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
    "T = (((X - 5) * 0.05 +  (X * 0.2) **5) / 5.0 - 5.5) / 6\n",
    "W = np.zeros((4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, error_sequence, W_sequence = gradient_descent_adam(\n",
    "       cubic_model, cubic_model_gradient, rmse, X, T, W, rho=1e-3, n_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016617411613005652"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_sequence[-1]\n",
    "#correct_err = 0.0184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and prepare the data.  The process is slightly modified from what we did in lecture.  Only using the first 46 samples (reduced to 43 after removing samples with missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip\n",
    "!unzip -o AirQualityUCI.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('AirQualityUCI.csv', delimiter=';', decimal=',',usecols=range(15), na_values=-200)\n",
    "data = data[['Time', 'CO(GT)']] # Only get the Time and CO(GT) column data, discard the rest\n",
    "data = data[:46]                # only use the first 46 samples\n",
    "data = data.dropna(axis=0)      # axis=0 -> Drop rows which contain missing values\n",
    "\n",
    "# Create numpy arrays for plotting.\n",
    "# Extract and format the data of interest\n",
    "\n",
    "# Get just the hour part of the time\n",
    "hour = np.array([int(t[:2]) for t in data['Time']])\n",
    "\n",
    "# Convert the pandas data into a numpy array\n",
    "CO = np.array(data['CO(GT)'])\n",
    "\n",
    "# Make sure the data is in a single column ... variable_num_rows, 1 column\n",
    "T = CO.reshape(-1, 1)\n",
    "X = hour.reshape(-1, 1)\n",
    "\n",
    "# Create labels for the data\n",
    "Tnames = ['CO']\n",
    "Xnames = ['Hour']\n",
    "\n",
    "# Print debug info\n",
    "print('X.shape =', X.shape, 'Xnames =', Xnames)\n",
    "print('T.shape =', T.shape, 'Tnames =', Tnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot `CO(GT)` air quality versus the hour of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot `CO(GT)` air quality versus the hour of the day to verify you have prepared the data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, T, '.')       # Plot CO vs Time, each data point is identified as '.'\n",
    "plt.grid(True)            # Display a grid on plot\n",
    "plt.title('CO vs Time')   # Add plot title\n",
    "plt.xlabel(Xnames[0])     # Add X-Axis label\n",
    "plt.ylabel(Tnames[0])     # Add Y-Axis label\n",
    "plt.show()                # Do this to suppress automatic plt text from last command run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add code cells here to implement the linear, quadratic, cubic, and quartic models, and to fit the models to the air quality data.\n",
    "\n",
    "Also add markdown cells that explain each result and summarize your observations of the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Your notebook will be run and graded automatically. Test this grading process by first downloading [A1grader.zip](http://www.cs.colostate.edu/~anderson/cs545/notebooks/A1grader.zip) and extract `A1grader.py` from it. Run the code in the following cell to demonstrate an example grading session. You should see a perfect execution score of 80/80 if your functions are defined correctly. The remaining 20 points will be based on other testing and the results you obtain and your discussions. \n",
    "\n",
    "A different, but similar, grading script will be used to grade your checked-in notebook. It will include additional tests. You should design and perform additional tests on all of your functions to be sure they run correctly before checking in your notebook.  \n",
    "\n",
    "For the grading script to run correctly, you must first name this notebook as 'Lastname-A1.ipynb' with 'Lastname' being your last name, and then save this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'Staab-A1.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "Testing\n",
      "  X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "  W = np.array([1, 2]).reshape(-1, 1)\n",
      "  Y = linear_model(X, W)\n",
      "\n",
      "--- 10/10 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "  X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "  W = np.array([1, 2, -3]).reshape(-1, 1)\n",
      "  Y = quadratic_model(X, W)\n",
      "\n",
      "--- 10/10 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "  X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "  W = np.array([1, 2, -3, 1.5).reshape(-1, 1)\n",
      "  Y = cubic_model(X, W)\n",
      "\n",
      "--- 10/10 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "  X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "  W = np.array([1, 2, -3, 1.5, 0.3]).reshape(-1, 1)\n",
      "  Y = quartic_model(X, W)\n",
      "\n",
      "--- 10/10 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "  X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "  T = (((X - 5) * 0.05 +  (X * 0.2) **5) / 5.0 - 5.5) / 6\n",
      "  W = np.array([1, 2, -3, 1.5, 0.3]).reshape(-1, 1)\n",
      "  grad = quartic_model_gradient(X, T, W)\n",
      "\n",
      "--- 10/10 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "   X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "   T = (((X - 5) * 0.05 +  (X * 0.2) **5) / 5.0 - 5.5) / 6\n",
      "   W = np.zeros((3, 1))\n",
      "   W, error_sequence, W_sequence = gradient_descent_adam(\n",
      "       quadratic_model, quadratic_model_gradient, rmse, X, T, W, rho=1e-3, n_steps=1000)\n",
      "\n",
      "--- 15/15 points. Returned correct values.\n",
      "\n",
      "Testing\n",
      "   X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "   T = (((X - 5) * 0.05 +  (X * 0.2) **5) / 5.0 - 5.5) / 6\n",
      "   W = np.zeros((4, 1))\n",
      "   W, error_sequence, W_sequence = gradient_descent_adam(\n",
      "       cubic_model, cubic_model_gradient, rmse, X, T, W, rho=1e-3, n_steps=10000)\n",
      "\n",
      "---  0/15 points. Returned incorrect values. Final error should be\n",
      "0.0184\n",
      "Your function returned\n",
      "0.016617411613005652\n",
      "\n",
      "A1 Execution Grade is 65 / 80\n",
      "\n",
      "Your final assignment grade will be based on other tests.  Run additional tests\n",
      "of your own design to check your functions before checking in this notebook.\n",
      "\n",
      "A1 FINAL GRADE is ___ / 100\n"
     ]
    }
   ],
   "source": [
    "%run -i A1grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check-In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not include this section in your notebook.\n",
    "\n",
    "Name your notebook ```Lastname-A1.ipynb```.  So, for me it would be ```Anderson-A1.ipynb```.  Submit the file using the ```Assignment 1``` link on [Canvas](https://colostate.instructure.com/courses/86986).\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * correct behavior of the required functions listed above,\n",
    "  * easy to understand plots in your notebook,\n",
    "  * readability of the notebook,\n",
    "  * effort in making interesting observations, and in formatting your notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
